{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "#sys.path.insert(0,\"..\")\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "try:\n",
    "    from torchvision.transforms import InterpolationMode\n",
    "\n",
    "    BICUBIC = InterpolationMode.BICUBIC\n",
    "except ImportError:\n",
    "    BICUBIC = Image.BICUBIC\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    return (\n",
    "        tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "    )\n",
    "\n",
    "\n",
    "def _convert_image_to_rgb(image):\n",
    "    return image.convert(\"RGB\")\n",
    "\n",
    "\n",
    "def preprocess_img(img):\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(448, BICUBIC),\n",
    "            transforms.CenterCrop(448),\n",
    "            #_convert_image_to_rgb,\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "    return transform(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scribbles_folder = './datasets/SCRIBBLES'\n",
    "scribbles_paths = sorted(glob.glob(scribbles_folder + \"/*.png\"))[::-1][:1000] # For heavy masking [::-1] \n",
    "scribbles_paths[:5]\n",
    "# https://github.com/hasibzunair/masksup-segmentation/blob/master/notebooks/exp_dataloader.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scribble = Image.open(scribbles_paths[2]).convert('P')\n",
    "scribble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scribble_pre = preprocess_img(scribble)\n",
    "scribble_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scribble_pre.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masked data loader experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from pipeline.dataset import DataSetMaskSup\n",
    "\n",
    "train_file = [\"data/voc07/trainval_voc07.json\"]\n",
    "test_file = [\"data/voc07/test_voc07.json\"]\n",
    "step_size = 4\n",
    "\n",
    "\n",
    "train_dataset = DataSetMaskSup(train_file, [\"randomflip\", \"resizedcrop\"], 448, \"voc07\")\n",
    "test_dataset = DataSetMaskSup(test_file, [], 448, \"voc07\")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=16, shuffle=True, num_workers=8\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=16, shuffle=False, num_workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = next(iter(train_loader))\n",
    "x = dt[\"img\"]\n",
    "xm = dt[\"masked_img\"]\n",
    "#s = dt[\"scribble\"]\n",
    "y = dt[\"target\"]\n",
    "\n",
    "x.shape, xm.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# def to_img(ten):\n",
    "#     ten =(ten[0].permute(1,2,0).detach().cpu().numpy()+1)/2\n",
    "#     ten=(ten*255).astype(np.uint8)\n",
    "#     return ten\n",
    "\n",
    "def unnormalize(tensor, mean, std):\n",
    "    for t, m, s in zip(tensor, mean, std):\n",
    "        t.mul_(s).add_(m)\n",
    "    return tensor\n",
    "\n",
    "def to_img_(ten):\n",
    "    curr_img = ten.detach().to(torch.device('cpu'))\n",
    "    curr_img = unnormalize(curr_img,\n",
    "                           torch.tensor([0, 0, 0]), # mean and std\n",
    "                           torch.tensor([1, 1, 1])) \n",
    "    curr_img = curr_img.permute((1, 2, 0))\n",
    "    return curr_img\n",
    "\n",
    "\n",
    "# a = to_img_(x[7])\n",
    "# print(a.shape)\n",
    "# plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = to_img_(x[7])\n",
    "print(a.shape)\n",
    "plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 5\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=n_images, \n",
    "                         sharex=True, sharey=True, figsize=(20, 2.5))\n",
    "\n",
    "for i in range(5):\n",
    "    axes[i].imshow(to_img_(x[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 5\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=n_images, \n",
    "                         sharex=True, sharey=True, figsize=(20, 2.5))\n",
    "\n",
    "for i in range(5):\n",
    "    axes[i].imshow(to_img_(xm[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_images = 5\n",
    "\n",
    "# fig, axes = plt.subplots(nrows=1, ncols=n_images, \n",
    "#                          sharex=True, sharey=True, figsize=(20, 2.5))\n",
    "\n",
    "# for i in range(5):\n",
    "#     axes[i].imshow(to_img_(s[i]), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = to_img_(s[0])\n",
    "# np.unique(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('maskrec')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35d972689a4ebd6112cf5bf9eea2c3bb189b2972b77b117bc02bba8b4bbbd65a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

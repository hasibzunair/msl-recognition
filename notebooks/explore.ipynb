{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "#sys.path.insert(0,\"..\")\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "try:\n",
    "    from torchvision.transforms import InterpolationMode\n",
    "\n",
    "    BICUBIC = InterpolationMode.BICUBIC\n",
    "except ImportError:\n",
    "    BICUBIC = Image.BICUBIC\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    return (\n",
    "        tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "    )\n",
    "\n",
    "\n",
    "def _convert_image_to_rgb(image):\n",
    "    return image.convert(\"RGB\")\n",
    "\n",
    "\n",
    "def preprocess_img(img):\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(448, BICUBIC),\n",
    "            transforms.CenterCrop(448),\n",
    "            #_convert_image_to_rgb,\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "    return transform(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scribbles_folder = './datasets/SCRIBBLES'\n",
    "scribbles_paths = sorted(glob.glob(scribbles_folder + \"/*.png\"))[::-1][:1000] # For heavy masking [::-1] \n",
    "scribbles_paths[:5]\n",
    "# https://github.com/hasibzunair/masksup-segmentation/blob/master/notebooks/exp_dataloader.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scribble = Image.open(scribbles_paths[2]).convert('P')\n",
    "scribble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scribble_pre = preprocess_img(scribble)\n",
    "scribble_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scribble_pre.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masked data loader experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Reproducibility ##########\n",
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from pipeline.dataset import DataSetMaskSup\n",
    "\n",
    "train_file = [\"data/voc07/trainval_voc07.json\"]\n",
    "test_file = [\"data/voc07/test_voc07.json\"]\n",
    "step_size = 4\n",
    "\n",
    "\n",
    "train_dataset = DataSetMaskSup(train_file, [\"randomflip\", \"resizedcrop\"], 448, \"voc07\")\n",
    "test_dataset = DataSetMaskSup(test_file, [], 448, \"voc07\")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=16, shuffle=True, num_workers=8\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=16, shuffle=False, num_workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = next(iter(test_loader))\n",
    "x = dt[\"img\"]\n",
    "xm = dt[\"masked_img\"]\n",
    "# xmo = dt[\"d\"]\n",
    "s = dt[\"scribble\"]\n",
    "y = dt[\"target\"]\n",
    "\n",
    "x.shape, xm.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# def to_img(ten):\n",
    "#     ten =(ten[0].permute(1,2,0).detach().cpu().numpy()+1)/2\n",
    "#     ten=(ten*255).astype(np.uint8)\n",
    "#     return ten\n",
    "\n",
    "def unnormalize(tensor, mean, std):\n",
    "    for t, m, s in zip(tensor, mean, std):\n",
    "        t.mul_(s).add_(m)\n",
    "    return tensor\n",
    "\n",
    "def to_img_(ten):\n",
    "    curr_img = ten.detach().to(torch.device('cpu'))\n",
    "    curr_img = unnormalize(curr_img,\n",
    "                           torch.tensor([0, 0, 0]), # mean and std\n",
    "                           torch.tensor([1, 1, 1])) \n",
    "    curr_img = curr_img.permute((1, 2, 0))\n",
    "    curr_img = curr_img.detach().cpu().numpy()\n",
    "    #print(np.unique(curr_img))\n",
    "    curr_img = (curr_img * 255).astype(np.uint8)\n",
    "    return curr_img\n",
    "\n",
    "\n",
    "# a = to_img_(x[7])\n",
    "# print(a.shape)\n",
    "# plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 5\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=n_images, \n",
    "                         sharex=True, sharey=True, figsize=(10, 5))\n",
    "\n",
    "for i in range(5):\n",
    "    axes[i].imshow(to_img_(x[i]))\n",
    "    axes[i].axis(\"off\")\n",
    "\n",
    "plt.savefig(\"./checkpoint/analysis/figures/images.pdf\", facecolor=\"white\", bbox_inches = 'tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 5\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=n_images, \n",
    "                         sharex=True, sharey=True, figsize=(10, 5))\n",
    "\n",
    "for i in range(5):\n",
    "    axes[i].imshow(to_img_(xm[i]))\n",
    "    axes[i].axis(\"off\")\n",
    "\n",
    "plt.savefig(\"./checkpoint/analysis/figures/images_masked_old.pdf\", facecolor=\"white\", bbox_inches = 'tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_images = 5\n",
    "\n",
    "# fig, axes = plt.subplots(nrows=1, ncols=n_images, \n",
    "#                          sharex=True, sharey=True, figsize=(10, 5))\n",
    "\n",
    "# for i in range(5):\n",
    "#     axes[i].imshow(to_img_(xm[i]))\n",
    "#     axes[i].axis(\"off\")\n",
    "\n",
    "# plt.savefig(\"./checkpoint/analysis/figures/images_masked.pdf\", facecolor=\"white\", bbox_inches = 'tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = to_img_(x[0])\n",
    "plt.imshow(a)\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\"./checkpoint/analysis/figures/img.png\", facecolor=\"white\", bbox_inches = 'tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = to_img_(xm[0])\n",
    "plt.imshow(b)\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\"./checkpoint/analysis/figures/masked_img.png\", facecolor=\"white\", bbox_inches = 'tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = to_img_(s[0])\n",
    "plt.imshow(c, cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\"./checkpoint/analysis/figures/scribble.png\", facecolor=\"white\", bbox_inches = 'tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "\n",
    "im = c\n",
    "row, col = im.shape[:2]\n",
    "bottom = im[row-2:row, 0:col]\n",
    "mean = cv2.mean(bottom)[0]\n",
    "bordersize = 5\n",
    "border = cv2.copyMakeBorder(\n",
    "    im,\n",
    "    top=bordersize,\n",
    "    bottom=bordersize,\n",
    "    left=bordersize,\n",
    "    right=bordersize,\n",
    "    borderType=cv2.BORDER_CONSTANT,\n",
    "    value=[0, 0, 0]\n",
    ")\n",
    "plt.imshow(border, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\"./checkpoint/analysis/figures/scribble.png\", facecolor=\"white\", bbox_inches = 'tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_images = 5\n",
    "\n",
    "# fig, axes = plt.subplots(nrows=1, ncols=n_images, \n",
    "#                          sharex=True, sharey=True, figsize=(10, 5))\n",
    "\n",
    "# for i in range(5):\n",
    "#     axes[i].imshow(to_img_(s[i]), cmap=\"gray\")\n",
    "#     axes[i].axis(\"off\")\n",
    "\n",
    "# plt.savefig(\"./checkpoint/analysis/figures/scribbles_thr.pdf\", facecolor=\"white\", bbox_inches = 'tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = to_img_(s[0])\n",
    "# np.unique(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASKED_PATH = \"./datasets/SCRIBBLES\"\n",
    "MASKED_PATHS = sorted(glob.glob(MASKED_PATH + \"/*.png\"))[::-1][:1000]\n",
    "len(MASKED_PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "\n",
    "def read_image(path):\n",
    "    image = cv2.imread(path, -1)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image\n",
    "\n",
    "images = []\n",
    "for i in range(40):\n",
    "    img = read_image(MASKED_PATHS[i])\n",
    "    images.append(img)\n",
    "    \n",
    "images = np.array(images)\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_image_grid(images, ncols=None, cmap='gray'):\n",
    "    '''Plot a grid of images'''\n",
    "    if not ncols:\n",
    "        factors = [i for i in range(1, len(images)+1) if len(images) % i == 0]\n",
    "        ncols = factors[len(factors) // 2] if len(factors) else len(images) // 4 + 1\n",
    "    nrows = int(len(images) / ncols) + int(len(images) % ncols)\n",
    "    imgs = [images[i] if len(images) > i else None for i in range(nrows * ncols)]\n",
    "    f, axes = plt.subplots(nrows, ncols, figsize=(3*ncols, 2*nrows))\n",
    "    axes = axes.flatten()[:len(imgs)]\n",
    "    for img, ax in zip(imgs, axes.flatten()): \n",
    "        if np.any(img):\n",
    "            if len(img.shape) > 2 and img.shape[2] == 1:\n",
    "                img = img.squeeze()\n",
    "            ax.imshow(img, cmap=cmap)\n",
    "            \n",
    "            # Hide grid lines\n",
    "            ax.grid(False)\n",
    "\n",
    "            # Hide axes ticks\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "            #f.tight_layout()\n",
    "            plt.subplots_adjust(left=0.4,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.1, \n",
    "                    hspace=0.01)\n",
    "    plt.savefig(\"./checkpoint/analysis/figures/masks.pdf\", facecolor=\"white\", bbox_inches = 'tight', dpi=300)\n",
    "\n",
    "# make 16 images with 60 height, 80 width, 3 color channels\n",
    "#images = np.random.rand(16, 60, 80, 3)\n",
    "\n",
    "# plot them\n",
    "plot_image_grid(images,  ncols=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('maskrec')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35d972689a4ebd6112cf5bf9eea2c3bb189b2972b77b117bc02bba8b4bbbd65a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
